resume:
test_checkpoint: 
checkpoint:      ./checkpoints
dataset:         'LibriTTS'

path:
  train_path:     ['filelists/LibriTTS-All/train-other-3-30.txt', 'filelists/LibriTTS-All/train-clean-3-30.txt'] 
  val_path:       ['filelists/LibriTTS-All/test-clean-librispeech-4-10.txt']
  test_path:      ['filelists/LibriTTS-All/test-clean-librispeech-4-10.txt']
  cmu_path:       'resources/cmu_dictionary'
  vocoder_path:   '../../../vocoder/hifigan'

preprocess:
  sample_rate: 22050
  n_mels:      80
  n_fft:       1024
  hop_length:  256
  win_length:  1024
  f_min:       0
  f_max:       8000

model:
  sil_token:   True
  add_blank:   True
  n_feats:     80
  n_spks:      0  # 108 for VCKT # 247 for Libri-TTS filelist and 1 for LJSpeech
  spk_emb_dim: 64

  tv_encoder: 
    c_in:      80 # 80, 768
    num_layer: 6
    c_h:       128
    c_out:     192
    c_out_g:   192 # 192 / 256
    commit_w:  0.25
    n_emb:     512

  lf0_encoder:
    c_in:      1
    c_h:       192    # match n_feat
    c_out:     192   # match encoder n_channels
    c_out_g:   192   # 192 / 256
    num_layer: 2

  tiv_encoder:
    c_in:      80 # 80, 768
    num_layer: 6
    c_h:       128    # 128 / 256
    c_out:     64  

  encoder:
    n_channels:         192    # 192 / 256
    filter_channels:    1024
    filter_channels_dp: 256
    n_layers:           8
    kernel_size:        3
    p_dropout:          0.1
    n_heads:            2
    window_size:        4
    use_softmax:        True
    use_decay:          False

  decoder:
    dim:        64    # 64 / 128
    pe_scale:   1000  # 1 for `grad-tts-old.pt` checkpoint
    dim_mults:  [1, 2]
    model_type: 'dit'  # vit | dit
    precond:    'edm'  # vp | ve | edm
    loss_type:  'base' # base | base_min_10 | base_log_10 | vmin_snr5 | min_snr_5 | snr | inv_snr |etc.. 

  dit:
    in_channels:     3
    patch_size:      3        # 3 | 7 | 15
    stride_size:     2        # 2 | 4 | 8
    overlap:         True
    hidden_size:     256      # 256 | 256 | 384 (256)
    depth:           4        # 1   | 2   | 4
    num_heads:       2        # 2   | 2   | 4
    mlp_ratio:       2        # 2   | 2   | 4
    out_channels:    1
    conv_pos:        16
    conv_pos_groups: 8
    use_decoder:     False
    mask_type:       'time_random'  # random | freq | time 


# model:
#   sil_token:   True
#   add_blank:   True
#   n_feats:     80
#   n_spks:      0  # 108 for VCKT # 247 for Libri-TTS filelist and 1 for LJSpeech
#   spk_emb_dim: 64

#   tv_encoder: 
#     c_in:      80 # 80, 768
#     num_layer: 6
#     c_h:       256
#     c_out:     256
#     c_out_g:   256 # 192 / 256
#     commit_w:  0.25
#     n_emb:     512

#   lf0_encoder:
#     c_in:      1
#     c_h:       256    # match n_feat
#     c_out:     256   # match encoder n_channels
#     c_out_g:   256   # 192 / 256
#     num_layer: 2

#   tiv_encoder:
#     c_in:      80 # 80, 768
#     num_layer: 6
#     c_h:       256    # 128 / 256
#     c_out:     64  

#   encoder:
#     n_channels:         256    # 192 / 256
#     filter_channels:    1024
#     filter_channels_dp: 256
#     n_layers:           8
#     kernel_size:        3
#     p_dropout:          0.1
#     n_heads:            2
#     window_size:        4
#     use_softmax:        True
#     use_decay:          False

#   decoder:
#     dim:        128    # 64 / 128
#     pe_scale:   1000  # 1 for `grad-tts-old.pt` checkpoint
#     dim_mults:  [1, 2]
#     model_type: 'dit'  # vit | dit
#     precond:    'edm'  # vp | ve | edm
#     loss_type:  'base' # base | base_min_10 | base_log_10 | vmin_snr5 | min_snr_5 | snr | inv_snr |etc.. 

#   dit:
#     in_channels:     3
#     patch_size:      3        # 3 | 7 | 15
#     stride_size:     2        # 2 | 4 | 8
#     overlap:         True
#     hidden_size:     384      # 256 | 256 | 384 (256)
#     depth:           4        # 1   | 2   | 4
#     num_heads:       2        # 2   | 2   | 4
#     mlp_ratio:       2        # 2   | 2   | 4
#     out_channels:    1
#     conv_pos:        16
#     conv_pos_groups: 8
#     use_decoder:     False
#     mask_type:       'time_random'  # random | freq | time 

train:
  epoch:       1000
  test_size:   16
  batch_size:  64 # 3254 60 // 72 //  96  32    
  save_epoch:  100
  eval_every:  100
  fix_len:     2
  ref_size:    3
  out_size:    True
  lr:          1e-4
  max_grad:    1
  amp:         False
  mask_ratio:  0   # 0.1 | 0.3 | 0.5 | 0.7
  ref_type:    'mel' # wav2vec2_1, wav2vec2_12  , wavlm_1, wavlm_12
  sty_type:    'mel'
  aug_type:    ['N', 'N', 'N']   # FTS | F | N
  mix_ratio:   -1
  threshold:   0.6895345449450861
  unseen_spk:  [18, 22, 44, 50, 55, 58, 64, 90, 93, 98]
  max_seq_len: 1000

test:
  spk_emb_path: '/phj/data/tts/vctk/preprocessed_data/spk_emb_dict.pkl'
  sample_eval:  True
  ema:          False
  n_spks:       108